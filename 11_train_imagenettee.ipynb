{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_10c import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet(te) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMAGENETTE_160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "tfms = [make_rgb, RandomResizedCrop(size, scale=(0.35,1)), np_to_float, PilRandomFlip()]\n",
    "\n",
    "bs = 64\n",
    "\n",
    "il = ImageList.from_files(path, tfms=tfms)\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name = 'val'))\n",
    "ll = label_by_func(sd, parent_labeler, proc_y=CategoryProcessor())\n",
    "\n",
    "ll.valid.x.tfms = [make_rgb, CenterCrop(size), np_to_float]\n",
    "\n",
    "data = ll.to_databunch(bs, c_in=3, c_out=10, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XResNet   \n",
    "X stands for mutant/extended version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![resnet tweaks](images/resnet_tweaks.JPG)  \n",
    "from the [Bag of Tricks for image classification paper](https://arxiv.org/abs/1812.01187)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already discusssed the Resnet-C tweak for the originial Resnet(left) above where using 3 3x3 convs leads to a better and faster result than a 7x7 conv with stride=2. Doing it the original way is super inefficient and it's just a single linear model which deosn't have that much richness to it. So we do the Resnet-C version where if you think about it, the receptive field of the final one is still gonna be 7x7 but its got there through a much richer set of features as we use 3x3 conv layers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  In Resnet-D...\n",
    "notice that you have an Avg pool and another conv layer on the right. Now THis is because if you're simply adding the identity block without any operation then you can not only change the no of channels on the left but also can't set the stride other than 1. Otherwise if wouldn't concatenate as they'd have different shapes. So what do we do? From time to time we add a conv layer w a stride=2 and double the no of channels at the same time and when do that we add to the identity path those two blocks. Avgpool layer causes the grid size to shift down by 2 in each dimension and 1x1 conv to double the no of channels. This approach gives you a nice little boost over the standard version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Resnet-B...\n",
    "Notice that you do a stride 2 in the scond conv layer and not the first(like in traditional resnet). Doing the stride 2 on a 1x1 conv is a terrible idea because you're literally throwing away 3 quarters of the data(BIG OOF!). This took people years to actually realize how a stride2 on the first conv layer is wasting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def noop(x): return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "    \n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size = ks, stride = stride, padding = ks//2, bias = bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "def init_cnn(m):\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)): nn.init.kaiming_normal_(m.weight)\n",
    "    for l in m.children(): init_cnn(l)\n",
    "        \n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf)\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn)\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BatchNorm part of the code above is interesting because you initialize the weights to be zero if zero_bn=True is passed and 1 otherwise. Why do we do that?(Refer Resnet-D)\n",
    "Looking at the Resblock function below, we see that after the last conv of each resblock we pass zero_bn=True thereby resulting in 0 as the output(everything gets multiplied by bn weights which is 0). SO now we're adding zero to the identity block; in other words the whole of resblock does nothing at all! Thats's a GREAT way to initialize a model. Because as we've seen, we don't want any layer to shift the mean and variance as we don't want our gradients to spiral off to zero/infinity. This way we ensure that our activations are literally the same all the way through. And thus we set the bn weight after the 3rd conv layer to be zero. This lets us train very deep models at very high learning rates. \n",
    "  \n",
    "Jeremy exclaims that nearly all academic literature talks about large batch sizes because companies google and openAI like to show off their data centers. But for us normal people, this stuff is interesting as it tells us how high a L.R. can we go to. A higher lr enables you to train faster and genralize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlock(nn.Module):\n",
    "    # expansion=1 implies its a resnet18/34 and if expansion=4 then its bigger\n",
    "    def __init__(self, expansion, ni, nh, stride=1):\n",
    "        super().__init__()\n",
    "        nf, ni = nh*expansion, ni*expansion\n",
    "        layers = [conv_layer(ni, nh, 3, stride=stride),### try ks=1\n",
    "                  conv_layer(nh, nf, 3, zero_bn=True, act=False)\n",
    "                  ] if expansion == 1 else [\n",
    "                  conv_layer(ni, nh, 1),\n",
    "                  conv_layer(nh, nh, 3, stride=stride),\n",
    "                  conv_layer(nh, nf, 1, zero_bn=True, act=False)]\n",
    "        self.convs = nn.Sequential(*layers)\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1, act=False) # if no of i/ps is different to the number of filters add a 1x1 conv layer\n",
    "        self.pool = noop if stride==1 else nn.AvgPool2d(2, ceil_mode=True) # if stride is not 1 then add AvgPooling\n",
    "        # when ceil_mode=True it uses ceil instead of floor to comput o/p shape\n",
    "        \n",
    "    def forward(self, x): return act_fn(self.convs(x)+ self.idconv(self.pool(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `(c_in+1)*8` as the number of filters in the second layer(see below) is interesting. If c_in=3 channels then the second layer contains 32 filters which is what the bag of tricks paper recommends. The *8 is there because Nvidia graphics cards like it when everything is in a multiple of 8(faster calculations probably). Also, if you tend to have a one channel input(b/w images) or a 5 channel input (in hyperspectral imaging) your second layer's filters are being dynamically changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class XResNet(nn.Sequential):\n",
    "    @classmethod\n",
    "    def create(cls, expansion, layers, c_in=3, c_out=1000):\n",
    "        nfs = [c_in, (c_in+1)*8, 64, 64] # filters for the first three layers\n",
    "        stem = [conv_layer(nfs[i], nfs[i+1], stride=2 if i==0 else 1)\n",
    "                          for i in range(3)] # stem is the start of the CNN\n",
    "        nfs = [64//expansion, 64, 128,256,512]\n",
    "        res_layers = [cls._make_layer(expansion, nfs[i], nfs[i+1],\n",
    "                                     n_blocks=1, stride=1 if i==0 else 2)\n",
    "                     for i,l in enumerate(layers)]\n",
    "        res = cls(\n",
    "        *stem,\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "        *res_layers,\n",
    "        nn.AdaptiveAvgPool2d(1), Flatten(),\n",
    "        nn.Linear(nfs[-1]*expansion, c_out),\n",
    "        )\n",
    "        init_cnn(res)\n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def _make_layer(expansion, ni, nf, n_blocks, stride):\n",
    "        return nn.Sequential(\n",
    "        *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "         for i in range(n_blocks)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0minit_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0minit_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minit_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/tutorials/fastai/course-v3/nbs/dl2/<ipython-input-7-78129aa8e697>\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??init_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def xresnet18(**kwargs): return XResNet.create(1, [2,2,2,2], **kwargs)\n",
    "def xresnet34(**kwargs): return XResNet.create(1, [3,4,6,3], **kwargs)\n",
    "def xresnet50(**kwargs): return XResNet.create(4, [3,4,6,3], **kwargs)\n",
    "def xresnet101(**kwargs): return XResNet.create(4, [3,4,23,3], **kwargs)\n",
    "def xresnet152(**kwargs): return XResNet.create(4, [3,8,36,3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for resnet18 and resnet34 each resblock has only 2 convs(Refer Resnet-D in image). In Resnet50 and above they squish the channels in the middle before increasing them so the layers would go like 64 filters, 16 and then 64 again. That's called as a bottleneck. The bottleneck block is the normal block for larger resnets. And 2 3x3 convs is the normal for smaller resnets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [partial(AvgStatsCallback, accuracy),\n",
    "       ProgressCallback,\n",
    "       CudaCallback,\n",
    "       partial(BatchTransformXCallback, norm_imagenette)]#, \n",
    "#        partial(MixUp, 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = LabelSmoothingCrossEntropy()\n",
    "arch = partial(xresnet18, c_out=10)\n",
    "opt_func = adam_opt(mom=0.9, mom_sqr = 0.99, eps = 1e-6, wd = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_batch(dl, learn):\n",
    "    learn.xb, learn.yb = next(iter(dl))\n",
    "    learn.do_begin_fit(0)\n",
    "    learn('begin_batch')\n",
    "    learn('after_fit')\n",
    "    return learn.xb, learn.yb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace the old `model_summary` since it use to take a `Runner` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def model_summary(learn, data, find_all=False, print_mod=False):\n",
    "    xb,yb = get_batch(data.valid_dl, learn)\n",
    "    mods = find_modules(learn.model, is_lin_layer) if find_all else learn.model.children()\n",
    "    f = lambda hook,mod,inp,out: print(f\"====\\n{mod}\\n\" if print_mod else \"\", out.shape)\n",
    "    with Hooks(mods, f) as hooks: learn.model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(arch(), data, loss_func, lr=1, cb_funcs=cbfs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([128, 32, 64, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 15.90 GiB total capacity; 170.95 MiB already allocated; 119.88 MiB free; 176.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4e4693651cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_mod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-e9f42605d668>\u001b[0m in \u001b[0;36mmodel_summary\u001b[0;34m(model, data, find_all, print_mod)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_lin_layer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfind_all\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'====\\n{mod}\\n'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprint_mod\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mHooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    340\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    341\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 342\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 15.90 GiB total capacity; 170.95 MiB already allocated; 119.88 MiB free; 176.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "learn.model = learn.model.cuda()\n",
    "model_summary(learn.model, data, print_mod=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====\n",
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      " torch.Size([128, 32, 64, 64])\n",
      "====\n",
      "Sequential(\n",
      "  (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      " torch.Size([128, 64, 64, 64])\n",
      "====\n",
      "Sequential(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      " torch.Size([128, 64, 64, 64])\n",
      "====\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      " torch.Size([128, 64, 32, 32])\n",
      "====\n",
      "Sequential(\n",
      "  (0): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      " torch.Size([128, 64, 32, 32])\n",
      "====\n",
      "Sequential(\n",
      "  (0): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (idconv): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      ")\n",
      " torch.Size([128, 128, 16, 16])\n",
      "====\n",
      "Sequential(\n",
      "  (0): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (idconv): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      ")\n",
      " torch.Size([128, 256, 8, 8])\n",
      "====\n",
      "Sequential(\n",
      "  (0): ResBlock(\n",
      "    (convs): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (idconv): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      ")\n",
      " torch.Size([128, 512, 4, 4])\n",
      "====\n",
      "AdaptiveAvgPool2d(output_size=1)\n",
      " torch.Size([128, 512, 1, 1])\n",
      "====\n",
      "Flatten()\n",
      " torch.Size([128, 512])\n",
      "====\n",
      "Linear(in_features=512, out_features=10, bias=True)\n",
      " torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "model_summary(learn.model, data, print_mod=True)\n",
    "# learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = partial(xresnet34, c_out=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(arch(), data, loss_func, lr=1, cb_funcs=cbfs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, cbs=[LR_Find(), Recorder()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_phases(phases):\n",
    "    phases = listify(phases)\n",
    "    return phases + [1-sum(phases)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.7]\n",
      "[0.3, 0.2, 0.5]\n"
     ]
    }
   ],
   "source": [
    "print(create_phases(0.3))\n",
    "print(create_phases([0.3,0.2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "pct_start = 0.5\n",
    "phases = create_phases(pct_start)\n",
    "sched_lr = combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5))\n",
    "sched_mom = combine_scheds(phases, cos_1cycle_anneal(0.95, 0.85, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbsched = [\n",
    "    ParamScheduler('lr', sched_lr),\n",
    "    ParamScheduler('mom', sched_mom)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without mixup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(arch(), data, loss_func, lr=lr, cb_funcs=cbfs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.746758</td>\n",
       "      <td>0.464463</td>\n",
       "      <td>1.638353</td>\n",
       "      <td>0.522803</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.490771</td>\n",
       "      <td>0.591826</td>\n",
       "      <td>2.177079</td>\n",
       "      <td>0.417070</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.412634</td>\n",
       "      <td>0.623931</td>\n",
       "      <td>1.803087</td>\n",
       "      <td>0.522038</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.314527</td>\n",
       "      <td>0.666068</td>\n",
       "      <td>2.233624</td>\n",
       "      <td>0.436688</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.242664</td>\n",
       "      <td>0.700496</td>\n",
       "      <td>1.431040</td>\n",
       "      <td>0.608917</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.164159</td>\n",
       "      <td>0.732601</td>\n",
       "      <td>1.861082</td>\n",
       "      <td>0.512866</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.079400</td>\n",
       "      <td>0.772943</td>\n",
       "      <td>1.242159</td>\n",
       "      <td>0.688662</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.991685</td>\n",
       "      <td>0.809800</td>\n",
       "      <td>1.026632</td>\n",
       "      <td>0.789554</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.907677</td>\n",
       "      <td>0.848030</td>\n",
       "      <td>0.906899</td>\n",
       "      <td>0.844331</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.855432</td>\n",
       "      <td>0.867040</td>\n",
       "      <td>0.897980</td>\n",
       "      <td>0.849172</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(10, cbsched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with MixUP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.921048</td>\n",
       "      <td>0.425494</td>\n",
       "      <td>1.761690</td>\n",
       "      <td>0.449936</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.727974</td>\n",
       "      <td>0.539022</td>\n",
       "      <td>1.511050</td>\n",
       "      <td>0.583439</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.670630</td>\n",
       "      <td>0.575140</td>\n",
       "      <td>1.772466</td>\n",
       "      <td>0.505987</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.587605</td>\n",
       "      <td>0.624353</td>\n",
       "      <td>1.683639</td>\n",
       "      <td>0.527134</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.540150</td>\n",
       "      <td>0.643046</td>\n",
       "      <td>1.438438</td>\n",
       "      <td>0.607388</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.463773</td>\n",
       "      <td>0.684866</td>\n",
       "      <td>1.349475</td>\n",
       "      <td>0.628025</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.392837</td>\n",
       "      <td>0.726370</td>\n",
       "      <td>1.095694</td>\n",
       "      <td>0.773758</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.330963</td>\n",
       "      <td>0.757841</td>\n",
       "      <td>1.016804</td>\n",
       "      <td>0.795669</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.259930</td>\n",
       "      <td>0.794487</td>\n",
       "      <td>0.941027</td>\n",
       "      <td>0.834395</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.221179</td>\n",
       "      <td>0.818566</td>\n",
       "      <td>0.923729</td>\n",
       "      <td>0.842293</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbfs = [partial(AvgStatsCallback, accuracy),\n",
    "       ProgressCallback,\n",
    "       CudaCallback,\n",
    "       partial(BatchTransformXCallback, norm_imagenette), \n",
    "       partial(MixUp, 0.2)]\n",
    "\n",
    "learn = Learner(arch(), data, loss_func, lr=lr, cb_funcs=cbfs, opt_func=opt_func)\n",
    "learn.fit(10, cbsched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn_learner  \n",
    "Refactoring it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cnn_learner(arch, data, loss_func, opt_func, c_in=None, c_out=None, lr=1e-2,\n",
    "               cuda=True, norm=None, progress=True, mixup=0, xtra_cb=None, **kwargs):\n",
    "    cbfs = [partial(AvgStatsCallback, accuracy)] + listify(xtra_cb)\n",
    "    if progress: cbfs.append(ProgressCallback)\n",
    "    if cuda: cbfs.append(CudaCallback)\n",
    "    if norm: cbfs.append(partial(BatchTransformXCallback, norm))\n",
    "    if mixup: cbfs.append(partial(MixUp, mixup))\n",
    "    arch_args = {}\n",
    "    if not c_in: c_in = data.c_in\n",
    "    if not c_out: c_out = data.c_out\n",
    "    if c_in: arch_args['c_in'] = c_in\n",
    "    if c_out: arch_args['c_out'] = c_out\n",
    "    return Learner(arch(**arch_args), data, loss_func, opt_func=opt_func, lr=lr, cb_funcs=cbfs, **kwargs)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(xresnet34, data, loss_func, opt_func, norm=norm_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      \n",
       "    </div>\n",
       "    \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.752833</td>\n",
       "      <td>0.464674</td>\n",
       "      <td>1.982242</td>\n",
       "      <td>0.427771</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.551207</td>\n",
       "      <td>0.563101</td>\n",
       "      <td>2.093762</td>\n",
       "      <td>0.433631</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.417543</td>\n",
       "      <td>0.615799</td>\n",
       "      <td>1.775300</td>\n",
       "      <td>0.511847</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.224483</td>\n",
       "      <td>0.701658</td>\n",
       "      <td>1.145202</td>\n",
       "      <td>0.745478</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.066336</td>\n",
       "      <td>0.774739</td>\n",
       "      <td>1.040329</td>\n",
       "      <td>0.782420</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5, cbsched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see all this put together in the fastai [imagenet training script](https://github.com/fastai/fastai/blob/master/examples/train_imagenet.py). It's the same as what we've seen so far, except it also handles multi-GPU training. So how well does this work?\n",
    "\n",
    "We trained for 60 epochs, and got an error of 5.9%, compared to the official PyTorch resnet which gets 7.5% error in 90 epochs! Our xresnet 50 training even surpasses standard resnet 152, which trains for 50% more epochs and has 3x as many layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 11_train_imagenette.ipynb to exp/nb_11.py\n"
     ]
    }
   ],
   "source": [
    "!./notebook2script.py 11_train_imagenette.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
